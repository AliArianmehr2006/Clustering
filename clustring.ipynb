{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0193cc96",
   "metadata": {},
   "source": [
    "# به نام خدا "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a74379",
   "metadata": {},
   "source": [
    "# فاز یک\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce890f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fea0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ویژگی‌های استخراج شده در d:\\University\\project\\hoshMohasebaty\\Clustering\\image_features_12.csv ذخیره شدند.\n",
      "تعداد تصاویر پردازش شده: 3600\n",
      "تعداد ویژگی‌های هر تصویر: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# تنظیمات مسیرها و پارامترها\n",
    "dataset_path = \"train\"  # مسیر اصلی دیتاست\n",
    "output_csv = os.path.join(os.getcwd(), \"image_features_12.csv\")  # مسیر ذخیره فایل خروجی\n",
    "classes = [\"beach\", \"dense_residential\", \"desert\", \"forest\", \"intersection\", \"sea_ice\"]  # لیست کلاس‌های تصاویر\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"\n",
    "    استخراج 12 ویژگی از تصویر بر اساس رنگ و بافت\n",
    "    \n",
    "    پارامترهای ورودی:\n",
    "        image: آرایه numpy از تصویر در فرمت RGB\n",
    "        \n",
    "    خروجی:\n",
    "        لیست 12 ویژگی به ترتیب زیر:\n",
    "        [میانگین قرمز، میانگین سبز، میانگین آبی، \n",
    "         واریانس قرمز، واریانس سبز، واریانس آبی،\n",
    "         انحراف معیار قرمز، انحراف معیار سبز، انحراف معیار آبی،\n",
    "         نسبت قرمز به سبز، نسبت سبز به آبی، نسبت قرمز به آبی]\n",
    "    \"\"\"\n",
    "    # 1. ویژگی‌های آماری کانال‌های رنگی\n",
    "    # میانگین رنگ‌ها - نشان دهنده غلظت کلی هر رنگ در تصویر\n",
    "    mean_r = np.mean(image[:,:,0])  # میانگین کانال قرمز\n",
    "    mean_g = np.mean(image[:,:,1])  # میانگین کانال سبز\n",
    "    mean_b = np.mean(image[:,:,2])  # میانگین کانال آبی\n",
    "    \n",
    "    # واریانس رنگ‌ها - نشان دهنده میزان پراکندگی مقادیر پیکسل‌ها\n",
    "    var_r = np.var(image[:,:,0])  # واریانس کانال قرمز\n",
    "    var_g = np.var(image[:,:,1])  # واریانس کانال سبز\n",
    "    var_b = np.var(image[:,:,2])  # واریانس کانال آبی\n",
    "    \n",
    "    # انحراف معیار رنگ‌ها - نشان دهنده میزان تغییرات رنگ\n",
    "    std_r = np.std(image[:,:,0])  # انحراف معیار کانال قرمز\n",
    "    std_g = np.std(image[:,:,1])  # انحراف معیار کانال سبز\n",
    "    std_b = np.std(image[:,:,2])  # انحراف معیار کانال آبی\n",
    "    \n",
    "    # 2. ویژگی‌های نسبتی - نشان دهنده تعادل بین رنگ‌ها\n",
    "    ratio_rg = mean_r / (mean_g + 1e-5)  # نسبت قرمز به سبز (برای جلوگیری از تقسیم بر صفر 1e-5 اضافه شده)\n",
    "    ratio_gb = mean_g / (mean_b + 1e-5)  # نسبت سبز به آبی\n",
    "    ratio_rb = mean_r / (mean_b + 1e-5)  # نسبت قرمز به آبی\n",
    "    \n",
    "    return [mean_r, mean_g, mean_b, \n",
    "            var_r, var_g, var_b,\n",
    "            std_r, std_g, std_b,\n",
    "            ratio_rg, ratio_gb, ratio_rb]\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"\n",
    "    خواندن تصویر و آماده‌سازی آن برای استخراج ویژگی‌ها\n",
    "    \n",
    "    پارامترهای ورودی:\n",
    "        image_path: مسیر کامل فایل تصویر\n",
    "        \n",
    "    خروجی:\n",
    "        لیست ویژگی‌های استخراج شده یا None در صورت بروز خطا\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # خواندن تصویر از دیسک\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"⚠️ خطا در خواندن تصویر: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # تبدیل رنگ از BGR (پیش‌فرض OpenCV) به RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return extract_features(image)\n",
    "    except Exception as e:\n",
    "        print(f\"خطا در پردازش {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# بخش اصلی کد - پردازش تمام تصاویر دیتاست\n",
    "data = []  # لیست برای ذخیره اطلاعات تمام تصاویر\n",
    "\n",
    "# پردازش هر کلاس از تصاویر\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"⚠️ پوشه {class_path} وجود ندارد!\")\n",
    "        continue  \n",
    "        \n",
    "    # پردازش هر تصویر در پوشه کلاس\n",
    "    for img_file in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_file) \n",
    "        \n",
    "        features = process_image(img_path)\n",
    "        \n",
    "        # اگر ویژگی‌ها با موفقیت استخراج شدند\n",
    "        if features is not None:\n",
    "            data.append({\n",
    "                \"class\": class_name,  # نام کلاس تصویر\n",
    "                \"filename\": img_file,  # نام فایل تصویر\n",
    "                \n",
    "                # ویژگی‌های رنگی\n",
    "                \"mean_r\": features[0],  # میانگین کانال قرمز\n",
    "                \"mean_g\": features[1],  # میانگین کانال سبز\n",
    "                \"mean_b\": features[2],  # میانگین کانال آبی\n",
    "                \n",
    "                # ویژگی‌های پراکندگی رنگ\n",
    "                \"var_r\": features[3],  # واریانس کانال قرمز\n",
    "                \"var_g\": features[4],  # واریانس کانال سبز\n",
    "                \"var_b\": features[5],  # واریانس کانال آبی\n",
    "                \n",
    "                # ویژگی‌های تغییرات رنگ\n",
    "                \"std_r\": features[6],  # انحراف معیار کانال قرمز\n",
    "                \"std_g\": features[7],  # انحراف معیار کانال سبز\n",
    "                \"std_b\": features[8],  # انحراف معیار کانال آبی\n",
    "                \n",
    "                # ویژگی‌های نسبتی\n",
    "                \"ratio_rg\": features[9],  # نسبت قرمز به سبز\n",
    "                \"ratio_gb\": features[10],  # نسبت سبز به آبی\n",
    "                \"ratio_rb\": features[11]  # نسبت قرمز به آبی\n",
    "            })\n",
    "\n",
    "# ذخیره نتایج در فایل CSV\n",
    "if data: \n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        \n",
    "        # نمایش گزارش نهایی\n",
    "        print(f\"✅ ویژگی‌های استخراج شده در {output_csv} ذخیره شدند.\")\n",
    "        print(f\"تعداد تصاویر پردازش شده: {len(df)}\")\n",
    "        print(f\"تعداد ویژگی‌های هر تصویر: 12\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(\"❌ خطای دسترسی! لطفاً:\")\n",
    "        print(\"1. فایل خروجی را اگر باز است ببندید\")\n",
    "        print(\"2. مسیر ذخیره متفاوتی انتخاب کنید\")\n",
    "        print(f\"مسیر پیشنهادی: {os.path.join(os.path.expanduser('~'), 'Desktop')}\")\n",
    "else:\n",
    "    print(\"❌ هیچ داده‌ای پردازش نشد!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3eb67b",
   "metadata": {},
   "source": [
    "# فاز دو"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a56f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1970bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ماتریس همبستگی بین 12 ویژگی:\n",
      "\n",
      "                mean_r     mean_g     mean_b      var_r      var_g      var_b      std_r      std_g      std_b   ratio_rg   ratio_gb   ratio_rb\n",
      "    mean_r       1.00       0.97       0.89      -0.05      -0.12      -0.11      -0.13      -0.21      -0.19       0.73       0.14       0.67\n",
      "    mean_g       0.97       1.00       0.96       0.06      -0.04      -0.02      -0.02      -0.12      -0.10       0.56       0.08       0.50\n",
      "    mean_b       0.89       0.96       1.00       0.19       0.10       0.13       0.13       0.04       0.07       0.49      -0.18       0.29\n",
      "     var_r      -0.05       0.06       0.19       1.00       0.94       0.89       0.97       0.92       0.88      -0.12      -0.41      -0.33\n",
      "     var_g      -0.12      -0.04       0.10       0.94       1.00       0.97       0.93       0.97       0.95      -0.13      -0.44      -0.37\n",
      "     var_b      -0.11      -0.02       0.13       0.89       0.97       1.00       0.89       0.95       0.97      -0.10      -0.48      -0.37\n",
      "     std_r      -0.13      -0.02       0.13       0.97       0.93       0.89       1.00       0.96       0.93      -0.15      -0.49      -0.41\n",
      "     std_g      -0.21      -0.12       0.04       0.92       0.97       0.95       0.96       1.00       0.98      -0.18      -0.50      -0.45\n",
      "     std_b      -0.19      -0.10       0.07       0.88       0.95       0.97       0.93       0.98       1.00      -0.15      -0.55      -0.45\n",
      "  ratio_rg       0.73       0.56       0.49      -0.12      -0.13      -0.10      -0.15      -0.18      -0.15       1.00       0.04       0.81\n",
      "  ratio_gb       0.14       0.08      -0.18      -0.41      -0.44      -0.48      -0.49      -0.50      -0.55       0.04       1.00       0.61\n",
      "  ratio_rb       0.67       0.50       0.29      -0.33      -0.37      -0.37      -0.41      -0.45      -0.45       0.81       0.61       1.00\n",
      "\n",
      " سه ویژگی بهینه انتخاب شده:\n",
      "1. mean_g\n",
      "2. ratio_rg\n",
      "3. ratio_gb\n",
      "\n",
      "نتایج در selected_features_12.csv ذخیره شدند.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# خواندن داده‌های فاز اول با 12 ویژگی\n",
    "df = pd.read_csv(\"image_features_12.csv\")\n",
    "\n",
    "# تابع محاسبه همبستگی (پیاده‌سازی دستی)\n",
    "def calculate_correlation(x, y):\n",
    "    \"\"\"\n",
    "    محاسبه ضریب همبستگی پیرسون بین دو ویژگی\n",
    "    ورودی:\n",
    "        x, y: دو آرایه numpy از ویژگی‌های مورد مقایسه\n",
    "    خروجی:\n",
    "        مقدار ضریب همبستگی بین دو ویژگی\n",
    "    \"\"\"\n",
    "    covariance = np.cov(x, y, bias=True)[0, 1]\n",
    "    std_x = np.std(x)\n",
    "    std_y = np.std(y)\n",
    "    return covariance / (std_x * std_y)\n",
    "\n",
    "# ایجاد ماتریس همبستگی\n",
    "def create_correlation_matrix(features):\n",
    "    \"\"\"\n",
    "    ایجاد ماتریس همبستگی بین تمام ویژگی‌ها\n",
    "    ورودی:\n",
    "        features: دیتافریم شامل ویژگی‌های عددی\n",
    "    خروجی:\n",
    "        corr_matrix: ماتریس همبستگی\n",
    "        feature_names: لیست نام ویژگی‌ها\n",
    "    \"\"\"\n",
    "    feature_names = features.columns\n",
    "    n_features = len(feature_names)\n",
    "    corr_matrix = np.zeros((n_features, n_features))\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            corr_matrix[i, j] = calculate_correlation(\n",
    "                features.iloc[:, i].values,\n",
    "                features.iloc[:, j].values\n",
    "            )\n",
    "    return corr_matrix, feature_names\n",
    "\n",
    "# تابع انتخاب ویژگی‌های بهینه\n",
    "def select_optimal_features(corr_matrix, feature_names, n_features=3, threshold=0.7):\n",
    "    \"\"\"\n",
    "    انتخاب ویژگی‌های بهینه بر اساس کمترین همبستگی\n",
    "    ورودی:\n",
    "        corr_matrix: ماتریس همبستگی\n",
    "        feature_names: لیست نام ویژگی‌ها\n",
    "        n_features: تعداد ویژگی‌های مورد نیاز\n",
    "        threshold: آستانه همبستگی برای حذف ویژگی‌های مشابه\n",
    "    خروجی:\n",
    "        لیست ویژگی‌های انتخاب شده\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    remaining = list(feature_names)\n",
    "    \n",
    "    while len(selected) < n_features and remaining:\n",
    "        # محاسبه میانگین همبستگی مطلق هر ویژگی با سایر ویژگی‌ها\n",
    "        avg_corrs = []\n",
    "        for i, feat in enumerate(remaining):\n",
    "            idx = list(feature_names).index(feat)\n",
    "            avg_corr = np.mean(np.abs([\n",
    "                corr_matrix[idx][list(feature_names).index(f)] \n",
    "                for f in remaining if f != feat\n",
    "            ]))\n",
    "            avg_corrs.append(avg_corr)\n",
    "        \n",
    "        # انتخاب ویژگی با کمترین میانگین همبستگی\n",
    "        best_idx = np.argmin(avg_corrs)\n",
    "        best_feature = remaining.pop(best_idx)\n",
    "        selected.append(best_feature)\n",
    "        \n",
    "        # حذف ویژگی‌های با همبستگی بالا با ویژگی انتخاب شده\n",
    "        remaining = [\n",
    "            f for f in remaining \n",
    "            if abs(corr_matrix[list(feature_names).index(best_feature)]\n",
    "                [list(feature_names).index(f)]) <= threshold\n",
    "        ]\n",
    "    \n",
    "    return selected[:n_features]\n",
    "\n",
    "# محاسبه ماتریس همبستگی برای 12 ویژگی\n",
    "numeric_features = df.drop(['class', 'filename'], axis=1)\n",
    "corr_matrix, feature_names = create_correlation_matrix(numeric_features)\n",
    "\n",
    "# نمایش ماتریس همبستگی به صورت متنی\n",
    "print(\"\\nماتریس همبستگی بین 12 ویژگی:\\n\")\n",
    "print(\"            \" + \" \".join([f\"{name[:10]:>10}\" for name in feature_names]))\n",
    "for i, name in enumerate(feature_names):\n",
    "    row = [f\"{corr:.2f}\" for corr in corr_matrix[i]]\n",
    "    print(f\"{name[:10]:>10} \" + \" \".join([f\"{val:>10}\" for val in row]))\n",
    "\n",
    "# انتخاب خودکار 3 ویژگی بهینه\n",
    "optimal_features = select_optimal_features(corr_matrix, feature_names)\n",
    "print(\"\\n سه ویژگی بهینه انتخاب شده:\")\n",
    "for i, feat in enumerate(optimal_features, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "# ذخیره نتایج\n",
    "selected_df = df[['class', 'filename'] + optimal_features]\n",
    "selected_df.to_csv('selected_features_12.csv', index=False)\n",
    "print(\"\\nنتایج در selected_features_12.csv ذخیره شدند.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5992f",
   "metadata": {},
   "source": [
    "# فاز سه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b4f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, MeanShift\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a21622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- خوشه‌بندی K-Means ---\n",
      "بهترین تعداد خوشه‌ها برای K-Means: 3\n",
      "\n",
      "--- خوشه‌بندی DBSCAN ---\n",
      "\n",
      "--- خوشه‌بندی Agglomerative ---\n",
      "\n",
      "--- خوشه‌بندی MeanShift ---\n",
      "\n",
      "--- تعداد خوشه‌ها ---\n",
      "K-Means: kmeans_cluster\n",
      "1    2279\n",
      "0     681\n",
      "2     640\n",
      "Name: count, dtype: int64\n",
      "DBSCAN: dbscan_cluster\n",
      " 0    3563\n",
      "-1      24\n",
      " 1      10\n",
      " 2       3\n",
      "Name: count, dtype: int64\n",
      "Agglomerative: agg_cluster\n",
      "0    2402\n",
      "2     639\n",
      "1     559\n",
      "Name: count, dtype: int64\n",
      "MeanShift: meanshift_cluster\n",
      "0    2232\n",
      "2     589\n",
      "1     519\n",
      "5     122\n",
      "3      98\n",
      "4      23\n",
      "8       9\n",
      "7       6\n",
      "6       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. آماده‌سازی داده‌ها\n",
    "try:\n",
    "    # بارگذاری داده‌ها از فایل CSV\n",
    "    data = pd.read_csv('selected_features_12.csv')\n",
    "    \n",
    "    # حذف ستون‌های 'class' و 'filename' از داده‌ها\n",
    "    features = data.drop(['class', 'filename'], axis=1)\n",
    "    \n",
    "    # فرض بر اینکه همه ویژگی‌ها بهینه هستند\n",
    "    optimal_features = features.columns.tolist()  \n",
    "    features = features[optimal_features]\n",
    "\n",
    "    # نرمال‌سازی داده‌ها با استفاده از StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"فایل 'selected_features_12.csv' پیدا نشد.\")\n",
    "except Exception as e:\n",
    "    print(f\"خطا در آماده‌سازی داده‌ها: {e}\")\n",
    "\n",
    "# 2. تنظیم هایپرپارامترها و خوشه‌بندی\n",
    "# الف) K-Means\n",
    "print(\"\\n--- خوشه‌بندی K-Means ---\")\n",
    "param_grid_kmeans = {\n",
    "    'n_clusters': range(2, 11),  # تعداد خوشه‌ها از 2 تا 10\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 20],\n",
    "    'max_iter': [300, 500]\n",
    "}\n",
    "\n",
    "best_kmeans = None\n",
    "best_score = -1\n",
    "\n",
    "for n_clusters in param_grid_kmeans['n_clusters']:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_kmeans = kmeans\n",
    "\n",
    "data['kmeans_cluster'] = best_kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# ذخیره مدل K-Means\n",
    "joblib.dump(best_kmeans, 'best_kmeans_model.joblib')\n",
    "\n",
    "print(f\"بهترین تعداد خوشه‌ها برای K-Means: {best_kmeans.n_clusters}\")\n",
    "\n",
    "# ب) DBSCAN\n",
    "print(\"\\n--- خوشه‌بندی DBSCAN ---\")\n",
    "# تعیین بهترین eps با استفاده از Nearest Neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X_scaled)\n",
    "distances, indices = nbrs.kneighbors(X_scaled)\n",
    "distances = np.sort(distances[:, 1], axis=0)\n",
    "\n",
    "# انتخاب eps و min_samples به صورت دستی\n",
    "eps = 0.5  # مقدار مناسب eps را بر اساس تحلیل انتخاب کنید\n",
    "min_samples = 5  # مقدار min_samples را نیز انتخاب کنید\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "data['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "# ذخیره مدل DBSCAN\n",
    "joblib.dump(dbscan, 'dbscan_model.joblib')\n",
    "\n",
    "# ج) Agglomerative Clustering\n",
    "print(\"\\n--- خوشه‌بندی Agglomerative ---\")\n",
    "agg = AgglomerativeClustering(n_clusters=best_kmeans.n_clusters, linkage='ward')\n",
    "agg_labels = agg.fit_predict(X_scaled)\n",
    "data['agg_cluster'] = agg_labels\n",
    "\n",
    "# ذخیره مدل Agglomerative\n",
    "joblib.dump(agg, 'agg_model.joblib')\n",
    "\n",
    "# د) MeanShift\n",
    "print(\"\\n--- خوشه‌بندی MeanShift ---\")\n",
    "meanshift = MeanShift(bandwidth=0.9)\n",
    "meanshift_labels = meanshift.fit_predict(X_scaled)\n",
    "data['meanshift_cluster'] = meanshift_labels\n",
    "\n",
    "# ذخیره مدل MeanShift\n",
    "joblib.dump(meanshift, 'meanshift_model.joblib')\n",
    "\n",
    "# 4. مقایسه نتایج\n",
    "try:\n",
    "    print(\"\\n--- تعداد خوشه‌ها ---\")\n",
    "    print(\"K-Means:\", pd.Series(data['kmeans_cluster']).value_counts())\n",
    "    print(\"DBSCAN:\", pd.Series(data['dbscan_cluster']).value_counts())\n",
    "    print(\"Agglomerative:\", pd.Series(data['agg_cluster']).value_counts())\n",
    "    print(\"MeanShift:\", pd.Series(data['meanshift_cluster']).value_counts())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"خطا در مقایسه نتایج: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
